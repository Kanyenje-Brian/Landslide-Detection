{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12572787,"sourceType":"datasetVersion","datasetId":7939827}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Landslide Detection Challenge - Starter Notebook\n\nWelcome to the Landslide Detection Challenge! This notebook will guide you through:\n1. Loading and exploring the multi-band dataset provided in `.npy` format.\n2. Visualizing the multi-band satellite data and understanding label distribution.\n3. Building and evaluating a baseline model to classify landslide and non-landslide images.\n\nLetâ€™s get started with loading and understanding the data!\n","metadata":{"id":"nODaxSas0JbR"}},{"cell_type":"markdown","source":"## Block 1: Import Libraries","metadata":{"id":"ejfTrwF10JbV"}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport plotly.express as px\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, f1_score, make_scorer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import load_model\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.ensemble import RandomForestClassifier\nimport tensorflow as tf\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"id":"K1NuFY_x0JbW","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:24:59.012913Z","iopub.execute_input":"2025-07-29T11:24:59.013294Z","iopub.status.idle":"2025-07-29T11:25:11.006428Z","shell.execute_reply.started":"2025-07-29T11:24:59.013262Z","shell.execute_reply":"2025-07-29T11:25:11.005434Z"}},"outputs":[{"name":"stderr","text":"2025-07-29 11:25:02.780666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753788303.029639    1353 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753788303.104897    1353 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Explanation\nWe import the required libraries:\n- **os**: for file and directory handling.\n- **numpy**: for numerical operations, particularly for loading `.npy` files.\n- **pandas**: for data handling with CSV files.\n- **matplotlib.pyplot**: for visualizing data, such as label distributions.\n- **sklearn.model_selection.train_test_split**: for splitting data into training and validation sets.\n- **tensorflow.keras**: for building and training a neural network model.\n","metadata":{"id":"sVQRf-ws0JbX"}},{"cell_type":"markdown","source":"## Block 2: Define Paths and Load CSV Files","metadata":{"id":"wAPsl4Si0JbY"}},{"cell_type":"code","source":"# Define paths for the dataset (remember to unzip the dataset first!)\ntrain_csv_path = '/kaggle/input/landslide-detection/Train.csv'  # Path to the training labels CSV file\ntest_csv_path = '/kaggle/input/landslide-detection/Test.csv'    # Path to the test image IDs CSV file\ntrain_data_path = '/kaggle/input/landslide-detection/train_data/train_data'  # Folder where .npy train files are located\ntest_data_path = '/kaggle/input/landslide-detection/test_data/test_data'    # Folder where .npy test files are located\n\n# Load Train.csv and inspect the data\ntrain_df = pd.read_csv(train_csv_path)\ntest_df = pd.read_csv(test_csv_path)\nprint(\"Train.csv:\")\nprint(train_df.head())","metadata":{"id":"xDyACVkf0JbY","outputId":"b803a45c-fecd-4ac3-bd8d-be6e802ee661","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:25:11.007891Z","iopub.execute_input":"2025-07-29T11:25:11.008795Z","iopub.status.idle":"2025-07-29T11:25:11.057459Z","shell.execute_reply.started":"2025-07-29T11:25:11.008757Z","shell.execute_reply":"2025-07-29T11:25:11.056278Z"}},"outputs":[{"name":"stdout","text":"Train.csv:\n          ID  label\n0  ID_HUD1ST      1\n1  ID_KGE2HY      1\n2  ID_VHV9BL      1\n3  ID_ZT0VEJ      0\n4  ID_5NFXVY      0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"id":"WRN5mqzw5wf8","outputId":"b6dd18be-3fee-45a2-9307-b223d809b9fc","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:25:12.701087Z","iopub.execute_input":"2025-07-29T11:25:12.701502Z","iopub.status.idle":"2025-07-29T11:25:12.716280Z","shell.execute_reply.started":"2025-07-29T11:25:12.701454Z","shell.execute_reply":"2025-07-29T11:25:12.714915Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"label\n0    5892\n1    1255\nName: count, dtype: int64"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"### Explanation\n- **Define Paths**: Specify paths to `Train.csv`, `Test.csv`, and folders containing `.npy` files for training and testing images.\n- **Load Train.csv**: We read the `Train.csv` file, which contains `ID` and `label` columns. The `label` is binary, indicating whether the image contains a landslide (1) or not (0).\n","metadata":{"id":"lPDktPhp0JbZ"}},{"cell_type":"markdown","source":"## Block 4: Load, Normalize, and Display Sample Multi-band Images","metadata":{"id":"jida8k-a0Jbb"}},{"cell_type":"code","source":"# Function to load and normalize .npy images\ndef load_and_normalize_npy_image(image_id, folder_path):\n    \"\"\"Loads a .npy file, normalizes each band, and returns the normalized image.\"\"\"\n    image_path = os.path.join(folder_path, f\"{image_id}.npy\")\n    img = np.load(image_path, mmap_mode='r')\n\n    img = img.astype('float32')  # ensure float for normalization\n\n    # Normalize per band (channels last)\n    min_vals = img.min(axis=(0, 1), keepdims=True)\n    max_vals = img.max(axis=(0, 1), keepdims=True)\n    img_normalized = (img - min_vals) / (max_vals - min_vals + 1e-8)\n\n    return img_normalized\n\n# Band descriptions\nband_descriptions = [\n    \"Red\", \"Green\", \"Blue\", \"Near Infrared\",\n    \"Descending VV (Vertical-Vertical)\", \"Descending VH (Vertical-Horizontal)\",\n    \"Descending Diff VV\", \"Descending Diff VH\",\n    \"Ascending VV (Vertical-Vertical)\", \"Ascending VH (Vertical-Horizontal)\",\n    \"Ascending Diff VV\", \"Ascending Diff VH\"\n]\n\nX = np.array([load_and_normalize_npy_image(image_id, train_data_path) for image_id in train_df['ID']])\ny = train_df['label'].values\nX_test = np.array([load_and_normalize_npy_image(image_id, test_data_path) for image_id in test_df['ID']])","metadata":{"id":"9SgOyTHP0Jbb","outputId":"a165535e-150e-4e3c-e815-e434a3f158b4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation\nThis block provides a complete view of the 12 individual bands with the corrected descriptions for ascending and descending radar bands.\n\n1. **Band Descriptions**:\n   - **Bands 1-4**: Visible and Near Infrared bands (Red, Green, Blue, NIR).\n   - **Bands 5-8**: Descending radar bands:\n     - **Band 5**: Descending VV (Vertical-Vertical polarization).\n     - **Band 6**: Descending VH (Vertical-Horizontal polarization).\n     - **Band 7**: Descending Diff VV.\n     - **Band 8**: Descending Diff VH.\n   - **Bands 9-12**: Ascending radar bands:\n     - **Band 9**: Ascending VV (Vertical-Vertical polarization).\n     - **Band 10**: Ascending VH (Vertical-Horizontal polarization).\n     - **Band 11**: Ascending Diff VV.\n     - **Band 12**: Ascending Diff VH.\n\n2. **Plotting Layout**:\n   - A 3x4 grid layout displays each band as a grayscale image.\n   - Each subplot includes the band number and description for easy reference.\n   - `plt.subplots_adjust` adds spacing between the plots to improve readability.\n","metadata":{"id":"zIsE_pDF0Jbc"}},{"cell_type":"markdown","source":"## Feature Extraction","metadata":{}},{"cell_type":"code","source":"# Path to the folder containing .npy images\n\ndef extract_features(img):\n    # img: (batch, H, W, 12)\n\n    # Bands 1-4: Optical\n    red, green, blue, nir = [img[:, :, :, i] for i in range(4)]\n    ndvi = (nir - red) / (nir + red + 1e-5)\n    ndwi = (green - nir) / (green + nir + 1e-5)\n\n    # Radar Descending\n    vv_desc, vh_desc = img[:, :, :, 4], img[:, :, :, 5]\n    vv_vh_ratio_desc = (vv_desc + 1e-5) / (vh_desc + 1e-5)\n\n    # Radar Ascending\n    vv_asc, vh_asc = img[:, :, :, 8], img[:, :, :, 9]\n    vv_vh_ratio_asc = (vv_asc + 1e-5) / (vh_asc + 1e-5)\n\n    # Expand NDVI etc. to (batch, H, W, 1) before concatenation\n    ndvi = ndvi[..., np.newaxis]\n    ndwi = ndwi[..., np.newaxis]\n    vv_vh_ratio_desc = vv_vh_ratio_desc[..., np.newaxis]\n    vv_vh_ratio_asc = vv_vh_ratio_asc[..., np.newaxis]\n\n    # Concatenate along channel axis\n    features = np.concatenate([img, ndvi, ndwi, vv_vh_ratio_desc, vv_vh_ratio_asc], axis=-1)\n    return features\n\n\nX_features = extract_features(X)\nX_features_test = extract_features(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Block 5: Prepare Data for Model Training","metadata":{"id":"SP3JYQyC0Jbc"}},{"cell_type":"code","source":"# Normalize\nX_train, X_val, y_train, y_val = train_test_split(\n    X_features, y_labels, \n    test_size=0.2, \n    stratify=y_labels, \n    random_state=SEED\n)\nX_train = X_train.astype('float32') / 255.0\nX_val = X_val.astype('float32') / 255.0\n\ntrain_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\ntrain_ds = train_ds.shuffle(1024).batch(BATCH_SIZE)\n\n# Add custom augmentations\ndef augment(image, label):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.rot90(image, tf.random.uniform([], 0, 4, dtype=tf.int32))\n    return image, label\n\ntrain_ds = train_ds.map(augment)\n\nval_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation\n\n1. **Load Data**:\n   - We define `load_npy_image` to load `.npy` files as raw images.\n   - `X` is created by loading each image using `load_npy_image` based on the image IDs in `train_df`.\n   - `y` contains the labels from `train_df`.\n\n2. **Stratified Data Split**:\n   - We split the data into `X_train`, `X_val`, `y_train`, and `y_val` while preserving class distribution using `stratify=y`.\n\n3. **ImageDataGenerator for Training**:\n   - `train_datagen` is configured with data augmentation options to increase the diversity of the training data.\n\n4. **ImageDataGenerator for Validation**:\n   - `val_datagen` loads the validation data without augmentation.\n\n5. **Generators**:\n   - `train_ds` and `val_ds` are created using `.flow()`, which yields data in batches for efficient training and validation.","metadata":{"id":"JvYIWDAb0Jbc"}},{"cell_type":"markdown","source":"## Block 6: Define and Compile a CNN Model with Focal Loss","metadata":{"id":"o6xK9j0k0Jbc"}},{"cell_type":"code","source":"# Precision\ndef precision_m(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.round(K.clip(y_pred, 0, 1))   # âœ… Threshold predictions\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n# Recall\ndef recall_m(y_true, y_pred):\n    y_true = K.cast(y_true, 'float32')\n    y_pred = K.round(K.clip(y_pred, 0, 1))   # âœ… Threshold predictions\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n# F1 Score\ndef f1_m(y_true, y_pred):\n    p = precision_m(y_true, y_pred)\n    r = recall_m(y_true, y_pred)\n    return 2 * ((p * r) / (p + r + K.epsilon()))\n\n# Define the Focal Loss function\ndef focal_loss(gamma=2.0, alpha=0.25):\n    \"\"\"\n    Focal Loss for binary classification.\n\n    Parameters:\n        gamma (float): Focusing parameter; typically set to 2.0.\n        alpha (float): Balancing factor; typically set to 0.25.\n\n    Returns:\n        Binary Focal Loss function.\n    \"\"\"\n    def focal_loss_fixed(y_true, y_pred):\n        # Clip predictions to prevent log(0)\n        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n\n        # Calculate p_t\n        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n\n        # Calculate focal loss\n        fl = -alpha * K.pow(1 - p_t, gamma) * K.log(p_t)\n        return K.mean(fl)\n\n    return focal_loss_fixed\n\nmodel = Sequential([\n    # First convolutional block\n    Input(shape=X_train.shape[1:]),\n    Conv2D(32, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    # Second convolutional block\n    Conv2D(64, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    # Third convolutional block\n    Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    # Fourth convolutional block for deeper feature extraction\n    Conv2D(256, (3, 3), activation='relu'),\n    BatchNormalization(),\n    MaxPooling2D((2, 2)),\n    Dropout(0.5),\n\n    # Flatten and add dense layers\n    Flatten(),\n    Dense(128, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),  # Dropout for regularization\n    Dense(64, activation='relu'),\n    BatchNormalization(),\n    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n])\n\n\n# Compile the model with Focal Loss and additional metrics\nmodel.compile(\n    optimizer='adam',\n    loss=focal_loss(gamma=2.0, alpha=0.5),\n    metrics=['accuracy']  # Additional metrics\n)\n\n# Display the model summary\nmodel.summary()","metadata":{"id":"uG2-yhmH0Jbc","outputId":"da9f574e-075f-4d44-fd8b-8b303249d880","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation\n\nThis code defines a Convolutional Neural Network (CNN) with custom metrics (Precision, Recall, and F1 Score) and **Focal Loss** for training, making it suitable for imbalanced datasets.\n\n#### Key Components\n\n1. **Custom Metrics**:\n   - `precision_m`: Calculates the proportion of true positive predictions out of all positive predictions, which helps evaluate the modelâ€™s accuracy in predicting positive (landslide) samples.\n   - `recall_m`: Measures the proportion of true positives out of all actual positives, reflecting the modelâ€™s ability to detect all positive cases.\n   - `f1_m`: Combines Precision and Recall into a single score using the harmonic mean, making it useful for evaluating the model on imbalanced datasets.\n\n2. **Focal Loss Function**:\n   - Focal Loss is designed to focus on hard-to-classify examples, making it particularly beneficial for imbalanced datasets.\n   - Parameters:\n     - `gamma=2.0`: Adjusts the focusing mechanism. Higher values place more focus on misclassified examples.\n     - `alpha=0.25`: Balances the contribution of positive and negative samples, ensuring the loss calculation doesnâ€™t get dominated by the majority class.\n   - The function `focal_loss_fixed` calculates Focal Loss by:\n     - Clipping predictions to avoid `log(0)`.\n     - Calculating the probability for each prediction (`p_t`), where correct predictions contribute less to the loss.\n     - Applying the focal scaling factor `(1 - p_t)^{\\gamma}` to emphasize harder examples in the loss computation.\n\n3. **CNN Model Architecture**:\n   - The CNN is designed with four convolutional blocks, each containing:\n     - **Conv2D layers**: Extract features with increasing complexity as the model goes deeper.\n     - **BatchNormalization layers**: Normalize activations, speeding up convergence and improving stability.\n     - **MaxPooling2D layers**: Down-sample feature maps, reducing spatial dimensions and capturing abstract patterns.\n     - **Dropout layers**: Applied with increasing rates, reducing overfitting by randomly deactivating nodes during training.\n   - Following the convolutional blocks:\n     - **Flatten**: Converts 2D feature maps to a 1D vector.\n     - **Dense layers**: Two fully connected layers with ReLU activation capture higher-level features, with Dropout for regularization.\n     - **Sigmoid Output Layer**: Used for binary classification, outputs the probability of each class (No Landslide or Landslide).\n\n4. **Model Compilation**:\n   - `optimizer='adam'`: An adaptive optimizer that adjusts the learning rate automatically during training.\n   - `loss=focal_loss(gamma=2.0, alpha=0.25)`: Focal Loss to handle class imbalance.\n   - `metrics=['accuracy', precision_m, recall_m, f1_m]`: Additional metrics for a comprehensive evaluation of the model's performance on imbalanced data.\n\n5. **Model Summary**:\n   - `model.summary()` displays the modelâ€™s architecture, showing layer types, output shapes, and parameter counts. This summary helps verify that the model structure matches expectations before training begins.","metadata":{"id":"Rg__4FUJ0Jbd"}},{"cell_type":"markdown","source":"## Block 7: Train the Model","metadata":{"id":"7ukG0Zjk0Jbd"}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n\n# Create a checkpoint callback that saves the best model based on validation loss\ncallback = [ModelCheckpoint(\n                \"kaggle/working/best_model.h5\",            \n                monitor='val_loss',   \n                verbose=1,                  \n                save_best_only=True,       \n                mode='min'),\n            \n            EarlyStopping(\n                monitor='val_loss', patience=5)\n           ]\n\n#class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n#class_weights_dict = dict(enumerate(class_weights))\n# Train the model using the generators with the checkpoint callback\nhistory = model.fit(\n    train_ds,       # Train generator\n    epochs=50,\n    validation_data=val_ds,  # Validation generator\n    callbacks=[callback],  # Include the checkpoint callback in training\n)\n","metadata":{"id":"qL32Y2Gi0Jbd","outputId":"e609cea7-aedd-4745-cc4b-f77b63690c41","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"IMG_SIZE = 224\nBATCH_SIZE = 32\nAUTOTUNE = tf.data.AUTOTUNE\nEPOCHS = 20\nN_SPLITS = 5\n\n# âœ… Encode labels\nclass_names = sorted(train_df['label'].unique())\nlabel_to_index = {name: i for i, name in enumerate(class_names)}\ntrain_df['label_idx'] = train_df['label'].map(label_to_index)\n\npaths = train_df['image_path'].values\nlabels = train_df['label_idx'].values\n\n# âœ… Load function\ndef load_image(path, label, training=True):\n    img = tf.io.read_file(path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n\n    if training:\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img, 0.2)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n\n    return img, label\n\n\ndef build_dataset(x_paths, y_labels, training=True):\n    ds = tf.data.Dataset.from_tensor_slices((x_paths, y_labels))\n    ds = ds.map(load_image, num_parallel_calls=AUTOTUNE)\n    if training:\n        ds = ds.shuffle(1024, seed=42)\n    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n    return ds\n\n# âœ… Model\ndef build_efficientnetb3():\n    base_model = tf.keras.applications.EfficientNetB3(\n        include_top=False,\n        weights=\"imagenet\",\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    base_model.trainable = False\n\n    inputs = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.3)(x)\n    outputs = tf.keras.layers.Dense(len(class_names), activation=\"softmax\")(x)\n\n    model = tf.keras.Model(inputs, outputs)\n    base_model.trainable = True\n    for layer in base_model.layers[:100]:\n        layer.trainable = False \n    model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-4),\n        loss=\"sparse_categorical_crossentropy\",\n        metrics=[\"accuracy\"]\n    )\n    return model\n\n# âœ… StratifiedKFold loop\nskf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(paths, labels)):\n    print(f\"\\nðŸ”¹ Fold {fold+1}/{N_SPLITS}\")\n    \n    train_paths, val_paths = paths[train_idx], paths[val_idx]\n    train_labels, val_labels = labels[train_idx], labels[val_idx]\n\n    train_ds = build_dataset(train_paths, train_labels, training=True)\n    val_ds = build_dataset(val_paths, val_labels, training=False)\n\n    # âœ… Compute class weights for this fold\n    cw_values = compute_class_weight(\n        class_weight='balanced',\n        classes=np.unique(train_labels),\n        y=train_labels\n    )\n    class_weights = dict(enumerate(cw_values))\n    print(\"Class Weights:\", class_weights)\n\n    # âœ… Build and train model\n    model = build_efficientnetb3()\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n    ]\n\n    model.fit(\n        train_ds,\n        validation_data=val_ds,\n        epochs=EPOCHS,\n        class_weight=class_weights,\n        callbacks=callbacks,\n        verbose=1\n    )\n\n    # Get predictions\n    y_true = []\n    y_pred = []\n    \n    for images, labels in val_ds:\n        preds = model.predict(images)\n        y_true.extend(labels.numpy())\n        y_pred.extend(np.argmax(preds, axis=1))\n    \n    # Compute F1\n    f1 = f1_score(y_true, y_pred) \n    print(\"Validation F1 Score:\", f1)\n    del model\n    gc.collect()\n    tf.keras.backend.clear_session()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation\n\n1. **Model Training**:\n   - `model.fit` is updated to use the `train_generator` and `val_generator`.\n   - `steps_per_epoch` and `validation_steps` control how many batches are processed per epoch for training and validation.\n2. **Efficiency**:\n   - Using a generator allows the model to load data in batches, reducing memory usage and making training feasible for large datasets.","metadata":{"id":"rDA2rhFy0Jbe"}},{"cell_type":"markdown","source":"## Block 8: Plot Training and Validation Accuracy","metadata":{"id":"HWs31OAA0Jbe"}},{"cell_type":"code","source":"def evaluate_model(model, X_test):\n\n    # Predict probabilities\n    y_pred = model.predict(X_test)\n    y_pred = (y_pred > 0.5).astype(int)\n    # Compute F1 score\n    f1 = f1_score(y_test, y_pred)\n    print(f\"F1 Score: {f1:.4f}\\n\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n    # Detailed report\n    print(classification_report(y_test, y_pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(val_gen)\ny_pred = (predictions > 0.5).astype(int)\ny_test = val_df['label']\ncm = confusion_matrix(val_df['label'], y_pred)\ndisp = ConfusionMatrixDisplay(cm)\ndisp.plot()\nprint(classification_report(y_test, y_pred))\nprint(f1_score(y_test, y_pred, average='binary'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def threshold_tuning(model):\n    scores = []\n    thresholds = np.linspace(0.1, 1, 10)\n    for thresh in thresholds:\n        y_pred = model.predict(X_test)\n        y_tuned = (y_pred > thresh).astype(int)\n        scores.append(f1_score(y_test, y_tuned))\n\n    fig = px.line(x=thresholds, y=scores, title='Threshold Tuning', template='plotly_white')\n    fig.update_traces(line=dict(color='red'))\n    fig.update_layout(xaxis_title='Thresholds',\n                      yaxis_title='F1 Scores',\n                      height=500,\n                      width=800)\n    \n    fig.show()\n\nthreshold_tuning(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training and validation accuracy and loss\nplt.figure(figsize=(12, 5))\n\n# Plot accuracy\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\n\n# Plot loss\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"TVNNaQvJ0Jbe","outputId":"a035e2f5-b66b-4a84-ab7c-8b16071c8628","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Explanation\nThis plot shows the **training and validation accuracy** as well as the **training and validation loss** over the epochs, allowing us to visually inspect the modelâ€™s learning behavior:\n\n- **Steady Improvements in Both Accuracy and Loss**: Consistent increases in accuracy and decreases in loss for both training and validation sets indicate effective learning and good generalization.\n\n- **Divergence Between Training and Validation Metrics**:\n  - If **training accuracy is high** but **validation accuracy is much lower** (with validation loss increasing), this suggests **overfitting**. The model may perform well on training data but fails to generalize to new data.\n  - If both **training and validation accuracy remain low** and losses are high, this indicates **underfitting**, meaning the model may not be complex enough to capture patterns in the data.\n\nThis combined plot of accuracy and loss offers a comprehensive view of model performance, helping us assess both how well the model fits the training data and how well it generalizes to new, unseen data.\n","metadata":{"id":"44qd1L2o0Jbe"}},{"cell_type":"markdown","source":"# Ensemble Methods","metadata":{}},{"cell_type":"code","source":"def load_image(image_id, folder_path):\n    image_path = os.path.join(folder_path, f\"{image_id}.npy\")\n    img = np.load(image_path, mmap_mode='r')\n    img = img.astype('float32')\n    return img\n\nX = np.array([load_image(image_id, train_data_path) for image_id in train_df['ID']])\ny = train_df['label'].values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:28:06.064084Z","iopub.execute_input":"2025-07-29T11:28:06.064701Z","iopub.status.idle":"2025-07-29T11:29:14.309221Z","shell.execute_reply.started":"2025-07-29T11:28:06.064661Z","shell.execute_reply":"2025-07-29T11:29:14.308136Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def extract_features(img):\n    # img: (batch, H, W, 12)\n\n    # Bands 1-4: Optical\n    red, green, blue, nir = [img[:, :, :, i] for i in range(4)]\n    ndvi = (nir - red) / (nir + red + 1e-5)\n    ndwi = (green - nir) / (green + nir + 1e-5)\n\n    # Radar Descending\n    vv_desc, vh_desc = img[:, :, :, 4], img[:, :, :, 5]\n    vv_vh_ratio_desc = (vv_desc + 1e-5) / (vh_desc + 1e-5)\n\n    # Radar Ascending\n    vv_asc, vh_asc = img[:, :, :, 8], img[:, :, :, 9]\n    vv_vh_ratio_asc = (vv_asc + 1e-5) / (vh_asc + 1e-5)\n\n    # Expand NDVI etc. to (batch, H, W, 1) before concatenation\n    ndvi = ndvi[..., np.newaxis]\n    ndwi = ndwi[..., np.newaxis]\n    vv_vh_ratio_desc = vv_vh_ratio_desc[..., np.newaxis]\n    vv_vh_ratio_asc = vv_vh_ratio_asc[..., np.newaxis]\n\n    # Concatenate along channel axis\n    features = np.concatenate([img, ndvi, ndwi, vv_vh_ratio_desc, vv_vh_ratio_asc], axis=-1)\n    return features\n\nX_features = extract_features(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:29:26.711274Z","iopub.execute_input":"2025-07-29T11:29:26.711675Z","iopub.status.idle":"2025-07-29T11:29:29.832816Z","shell.execute_reply.started":"2025-07-29T11:29:26.711642Z","shell.execute_reply":"2025-07-29T11:29:29.831756Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def means(df, X):\n    # Bands 4 to 12 â†’ index 3 to 11\n    for i, band in enumerate(range(3, 12)):\n        df[f'band{band+1}_mean'] = X[:, :, :, band].mean(axis=(1, 2))\n        df[f'band{band+1}_std']  = X[:, :, :, band].std(axis=(1, 2))\n        df[f'band{band+1}_min']  = X[:, :, :, band].min(axis=(1, 2))\n        df[f'band{band+1}_max']  = X[:, :, :, band].max(axis=(1, 2))\n\n    # Derived features (NDVI, NDWI, radar)\n    for name, idx in zip(['ndvi', 'ndwi', 'vv_vh_desc', 'vv_ch_asc'], [12, 13, 14, 15]):\n        df[f'{name}_mean'] = X[:, :, :, idx].mean(axis=(1, 2))\n        df[f'{name}_std']  = X[:, :, :, idx].std(axis=(1, 2))\n        df[f'{name}_min']  = X[:, :, :, idx].min(axis=(1, 2))\n        df[f'{name}_max']  = X[:, :, :, idx].max(axis=(1, 2))\n\n    return df\n\n\n# Apply to training dataframe\ntraining_df = means(train_df, X_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:30:01.076429Z","iopub.execute_input":"2025-07-29T11:30:01.076851Z","iopub.status.idle":"2025-07-29T11:30:13.139225Z","shell.execute_reply.started":"2025-07-29T11:30:01.076818Z","shell.execute_reply":"2025-07-29T11:30:13.137869Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold\nfrom xgboost import XGBClassifier\nimport optuna\n\nX_df = training_df.drop(columns=['ID','label'])\ny_df = training_df['label']\nX_train, X_val, y_train, y_val = train_test_split(X_df, y_df, random_state=42)\nxgb =XGBClassifier(random_state=42)\nxgb.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:31:14.311777Z","iopub.execute_input":"2025-07-29T11:31:14.312198Z","iopub.status.idle":"2025-07-29T11:31:16.304266Z","shell.execute_reply.started":"2025-07-29T11:31:14.312160Z","shell.execute_reply":"2025-07-29T11:31:16.303247Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)","text/html":"<style>#sk-container-id-1 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-1 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-1 pre {\n  padding: 0;\n}\n\n#sk-container-id-1 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-1 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-1 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-1 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-1 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-1 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-1 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-1 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-1 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-1 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-1 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-1 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n#sk-container-id-1 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-1 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-1 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-1 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-1 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-1 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-1 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-1 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\ndef cross_validate_model(model, X, y, n_splits=5, random_state=42):\n\n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n    \n    oof_preds = np.zeros_like(y, dtype=float)\n    f1_scores, acc_scores = [], []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n        print(f\"Fold {fold+1}/{n_splits}\")\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n\n        \n        # Fit model\n        model.fit(X_train, y_train)\n        \n        # Predict probabilities or classes\n        y_pred = model.predict(X_val)\n        \n        # Save OOF predictions\n        oof_preds[val_idx] = y_pred\n        \n        # Compute metrics\n        f1 = f1_score(y_val, y_pred, average='binary')\n        acc = accuracy_score(y_val, y_pred)\n        f1_scores.append(f1)\n        acc_scores.append(acc)\n        \n        print(f\"Fold {fold+1} F1: {f1:.4f} | Accuracy: {acc:.4f}\")\n    \n    print(\"=\"*40)\n    print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n    print(f\"Mean Accuracy: {np.mean(acc_scores):.4f}\")\n    \n\ncross_validate_model(xgb, X_df, y_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:22:26.248719Z","iopub.execute_input":"2025-07-29T12:22:26.249080Z","iopub.status.idle":"2025-07-29T12:22:29.520962Z","shell.execute_reply.started":"2025-07-29T12:22:26.249046Z","shell.execute_reply":"2025-07-29T12:22:29.520041Z"}},"outputs":[{"name":"stdout","text":"Fold 1/5\nFold 1 F1: 0.8247 | Accuracy: 0.9406\nFold 2/5\nFold 2 F1: 0.8103 | Accuracy: 0.9385\nFold 3/5\nFold 3 F1: 0.8069 | Accuracy: 0.9377\nFold 4/5\nFold 4 F1: 0.8178 | Accuracy: 0.9370\nFold 5/5\nFold 5 F1: 0.8145 | Accuracy: 0.9391\n========================================\nMean F1 Score: 0.8149\nMean Accuracy: 0.9386\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"def evaluate_model(model, X_test, y_test):\n\n    # Predict probabilities\n    y_pred = model.predict(X_test)\n\n    # Compute F1 score\n    f1 = f1_score(y_test, y_pred)\n    print(f\"F1 Score: {f1:.4f}\\n\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(6,5))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n\n    # Detailed report\n    print(classification_report(y_test, y_pred))\n\n\nevaluate_model(xgb, X_val, y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:31:33.559920Z","iopub.execute_input":"2025-07-29T11:31:33.560331Z","iopub.status.idle":"2025-07-29T11:31:33.861328Z","shell.execute_reply.started":"2025-07-29T11:31:33.560296Z","shell.execute_reply":"2025-07-29T11:31:33.860178Z"}},"outputs":[{"name":"stdout","text":"F1 Score: 0.9522\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 600x500 with 2 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      1484\n           1       0.99      0.92      0.95       303\n\n    accuracy                           0.98      1787\n   macro avg       0.98      0.96      0.97      1787\nweighted avg       0.98      0.98      0.98      1787\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from optuna.samplers import RandomSampler\ndef objective(trial):\n    params = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 1, 10),\n        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-8, 10.0, log=True),\n        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True),\n        \"random_state\": 42,\n\n    }\n\n    f1_scores = []\n\n    model = XGBClassifier(**params)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        verbose=False\n        )\n\n    y_pred = model.predict(X_val)\n    f1_scores.append(f1_score(y_val, y_pred))\n\n    return np.mean(f1_scores)\n\noptuna.logging.set_verbosity(optuna.logging.CRITICAL)\n\nstudy = optuna.create_study(direction=\"maximize\", sampler=RandomSampler())\nstudy.optimize(objective, n_trials=30)\n\nprint(\"Best F1:\", study.best_value)\nprint(\"Best Params:\", study.best_params)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:31:42.462852Z","iopub.execute_input":"2025-07-29T11:31:42.463245Z","iopub.status.idle":"2025-07-29T11:32:01.530851Z","shell.execute_reply.started":"2025-07-29T11:31:42.463200Z","shell.execute_reply":"2025-07-29T11:32:01.529719Z"}},"outputs":[{"name":"stdout","text":"Best F1: 0.8074324324324325\nBest Params: {'max_depth': 10, 'learning_rate': 0.10661179456187067, 'subsample': 0.8416700191360948, 'colsample_bytree': 0.9640985929364909, 'min_child_weight': 8.756812202253448, 'gamma': 0.2726507389828253, 'reg_lambda': 0.00018854415325127594, 'reg_alpha': 7.782056480293808e-07}\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"best_xgb = XGBClassifier(**study.best_params)\ncross_validate_model(best_xgb, X_df, y_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:23:28.700810Z","iopub.execute_input":"2025-07-29T12:23:28.701212Z","iopub.status.idle":"2025-07-29T12:23:35.638361Z","shell.execute_reply.started":"2025-07-29T12:23:28.701171Z","shell.execute_reply":"2025-07-29T12:23:35.637377Z"}},"outputs":[{"name":"stdout","text":"Fold 1/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning:\n\n[12:23:28] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"min_child_samples\", \"num_leaves\" } are not used.\n\n\n","output_type":"stream"},{"name":"stdout","text":"Fold 1 F1: 0.8230 | Accuracy: 0.9399\nFold 2/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning:\n\n[12:23:30] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"min_child_samples\", \"num_leaves\" } are not used.\n\n\n","output_type":"stream"},{"name":"stdout","text":"Fold 2 F1: 0.8077 | Accuracy: 0.9371\nFold 3/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning:\n\n[12:23:31] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"min_child_samples\", \"num_leaves\" } are not used.\n\n\n","output_type":"stream"},{"name":"stdout","text":"Fold 3 F1: 0.8305 | Accuracy: 0.9440\nFold 4/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning:\n\n[12:23:32] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"min_child_samples\", \"num_leaves\" } are not used.\n\n\n","output_type":"stream"},{"name":"stdout","text":"Fold 4 F1: 0.8272 | Accuracy: 0.9412\nFold 5/5\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/xgboost/core.py:160: UserWarning:\n\n[12:23:34] WARNING: /workspace/src/learner.cc:742: \nParameters: { \"min_child_samples\", \"num_leaves\" } are not used.\n\n\n","output_type":"stream"},{"name":"stdout","text":"Fold 5 F1: 0.8410 | Accuracy: 0.9468\n========================================\nMean F1 Score: 0.8259\nMean Accuracy: 0.9418\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"def threshold_tuning(model, X_test, y_test):\n    scores = []\n    thresholds = np.linspace(0.1, 1, 10)\n    for thresh in thresholds:\n        y_pred = model.predict_proba(X_test)[:, 1]\n        y_tuned = (y_pred > thresh).astype(int)\n        scores.append(f1_score(y_test, y_tuned))\n\n    fig = px.line(x=thresholds, y=scores, title='Threshold Tuning', template='plotly_white')\n    fig.update_traces(line=dict(color='red'))\n    fig.update_layout(xaxis_title='Thresholds',\n                      yaxis_title='F1 Scores',\n                      height=500,\n                      width=800)\n    \n    fig.show()\n\nthreshold_tuning(best_lgbm, X_val, y_val)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:23:51.209686Z","iopub.execute_input":"2025-07-29T12:23:51.210034Z","iopub.status.idle":"2025-07-29T12:23:51.659713Z","shell.execute_reply.started":"2025-07-29T12:23:51.209996Z","shell.execute_reply":"2025-07-29T12:23:51.658763Z"}},"outputs":[{"output_type":"display_data","data":{"text/html":"<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1b4f61b2-1b3d-4de3-a295-b519694897c8\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b4f61b2-1b3d-4de3-a295-b519694897c8\")) {                    Plotly.newPlot(                        \"1b4f61b2-1b3d-4de3-a295-b519694897c8\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"line\":{\"color\":\"red\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.1,0.2,0.30000000000000004,0.4,0.5,0.6,0.7000000000000001,0.8,0.9,1.0],\"xaxis\":\"x\",\"y\":[0.7956656346749226,0.8006430868167203,0.7986688851913477,0.807495741056218,0.8075601374570447,0.8027923211169284,0.7949640287769785,0.7830882352941176,0.7721280602636534,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Thresholds\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"F1 Scores\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Threshold Tuning\"},\"height\":500,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('1b4f61b2-1b3d-4de3-a295-b519694897c8');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                            </script>        </div>\n</body>\n</html>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import shap\n\nexplainer = shap.TreeExplainer(best_xgb)\nshap_values = explainer.shap_values(X_train)\n\nshap.summary_plot(shap_values, X_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## LGB","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\n# 1ï¸âƒ£ Train LightGBM\nlgb_model = LGBMClassifier(n_estimators=500, max_depth=-1, learning_rate=0.05)\nlgb_model.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:32:47.056095Z","iopub.execute_input":"2025-07-29T11:32:47.056463Z","iopub.status.idle":"2025-07-29T11:32:55.477060Z","shell.execute_reply.started":"2025-07-29T11:32:47.056437Z","shell.execute_reply":"2025-07-29T11:32:55.475920Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 952, number of negative: 4408\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003349 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 5360, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177612 -> initscore=-1.532611\n[LightGBM] [Info] Start training from score -1.532611\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"LGBMClassifier(learning_rate=0.05, n_estimators=500)","text/html":"<style>#sk-container-id-2 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-2 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-2 pre {\n  padding: 0;\n}\n\n#sk-container-id-2 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-2 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-2 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-2 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-2 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-2 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-2 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-2 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-2 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-2 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-2 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"â–¸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-2 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"â–¾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n#sk-container-id-2 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-2 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-2 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-2 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-2 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-2 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-2 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-2 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=500)</pre></div> </div></div></div></div>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"cross_validate_model(lgb_model, X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:33:13.478226Z","iopub.execute_input":"2025-07-29T11:33:13.479288Z","iopub.status.idle":"2025-07-29T11:33:24.951261Z","shell.execute_reply.started":"2025-07-29T11:33:13.479252Z","shell.execute_reply":"2025-07-29T11:33:24.949780Z"}},"outputs":[{"name":"stdout","text":"Fold 1/5\n[LightGBM] [Info] Number of positive: 762, number of negative: 3526\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001484 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 4288, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177705 -> initscore=-1.531973\n[LightGBM] [Info] Start training from score -1.531973\nFold 1 F1: 0.8268 | Accuracy: 0.9422\nFold 2/5\n[LightGBM] [Info] Number of positive: 762, number of negative: 3526\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001587 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 4288, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177705 -> initscore=-1.531973\n[LightGBM] [Info] Start training from score -1.531973\nFold 2 F1: 0.8394 | Accuracy: 0.9468\nFold 3/5\n[LightGBM] [Info] Number of positive: 762, number of negative: 3526\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001535 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 4288, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177705 -> initscore=-1.531973\n[LightGBM] [Info] Start training from score -1.531973\nFold 3 F1: 0.7865 | Accuracy: 0.9291\nFold 4/5\n[LightGBM] [Info] Number of positive: 761, number of negative: 3527\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001547 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 4288, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177472 -> initscore=-1.533570\n[LightGBM] [Info] Start training from score -1.533570\nFold 4 F1: 0.8338 | Accuracy: 0.9431\nFold 5/5\n[LightGBM] [Info] Number of positive: 761, number of negative: 3527\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002488 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 13260\n[LightGBM] [Info] Number of data points in the train set: 4288, number of used features: 52\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.177472 -> initscore=-1.533570\n[LightGBM] [Info] Start training from score -1.533570\nFold 5 F1: 0.8424 | Accuracy: 0.9487\n========================================\nMean F1 Score: 0.8258\nMean Accuracy: 0.9420\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def objective(trial):\n    params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 200, 1000),\n        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 15),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 50),\n        \"verbose\": -1\n    }\n\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n\n\n    model = LGBMClassifier(**params, random_state=42)\n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        eval_metric='binary_logloss',\n        callbacks=[]\n        )\n\n    y_pred = model.predict(X_val)\n    f1_scores.append(f1_score(y_val, y_pred))\n\n    return np.mean(f1_scores)\n\n    return np.mean(f1_scores)\n\noptuna.logging.set_verbosity(optuna.logging.CRITICAL)\n\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=30)\n\nprint(\"Best F1:\", study.best_value)\nprint(\"Best Params:\", study.best_params)\n\nbest_params = study.best_params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:35:35.718365Z","iopub.execute_input":"2025-07-29T11:35:35.719954Z","iopub.status.idle":"2025-07-29T11:36:26.223167Z","shell.execute_reply.started":"2025-07-29T11:35:35.719906Z","shell.execute_reply":"2025-07-29T11:36:26.221992Z"}},"outputs":[{"name":"stdout","text":"Best F1: 0.8223350253807107\nBest Params: {'n_estimators': 528, 'learning_rate': 0.18455718190038914, 'max_depth': 4, 'num_leaves': 81, 'subsample': 0.7794575206168013, 'colsample_bytree': 0.6622664514555144, 'min_child_samples': 46}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"best_lgbm = LGBMClassifier(**study.best_params)\ncross_validate_model(best_lgbm, X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Block 9: Make Predictions on the Test Set and Prepare Submission","metadata":{"id":"rxJ3bFl30Jbe"}},{"cell_type":"code","source":"def load_and_extract_features(df, X):\n\n    X = extract_features(X\n                        )\n    for i, band in enumerate(range(3, 12)):\n        df[f'band{band+1}_mean'] = X[:, :, :, band].mean(axis=(1, 2))\n        df[f'band{band+1}_std']  = X[:, :, :, band].std(axis=(1, 2))\n        df[f'band{band+1}_min']  = X[:, :, :, band].min(axis=(1, 2))\n        df[f'band{band+1}_max']  = X[:, :, :, band].max(axis=(1, 2))\n\n    # Derived features (NDVI, NDWI, radar)\n    for name, idx in zip(['ndvi', 'ndwi', 'vv_vh_desc', 'vv_ch_asc'], [12, 13, 14, 15]):\n        df[f'{name}_mean'] = X[:, :, :, idx].mean(axis=(1, 2))\n        df[f'{name}_std']  = X[:, :, :, idx].std(axis=(1, 2))\n        df[f'{name}_min']  = X[:, :, :, idx].min(axis=(1, 2))\n        df[f'{name}_max']  = X[:, :, :, idx].max(axis=(1, 2))\n\n    return df\n\nX_test_arrays = np.array([load_image(image_id, test_data_path) for image_id in test_df['ID']])\nX_pred = load_and_extract_features(test_df, X_test_arrays)\nX_preds = X_pred.drop(columns=['ID'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T11:48:13.859092Z","iopub.execute_input":"2025-07-29T11:48:13.860129Z","iopub.status.idle":"2025-07-29T11:48:45.057791Z","shell.execute_reply.started":"2025-07-29T11:48:13.860084Z","shell.execute_reply":"2025-07-29T11:48:45.056583Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def stratifiedKFold(model):\n    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    f1_scores = []\n    test_preds = []\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(X_df, y_df)):\n        print(f\"Fold {fold+1}\")\n    \n        # Use the same DataFrames as in split\n        X_tr, X_val = X_df.iloc[train_idx], X_df.iloc[val_idx]\n        y_tr, y_val = y_df.iloc[train_idx], y_df.iloc[val_idx]\n    \n        model.fit(\n            X_tr, y_tr,\n            eval_set=[(X_val, y_val)],\n        )\n    \n        # Validation predictions and F1\n        y_pred_val = model.predict(X_val)\n        f1 = f1_score(y_val, y_pred_val)\n        f1_scores.append(f1)\n        print(f\"Fold {fold+1} F1: {f1:.4f}\")\n    \n        # Test predictions (probabilities)\n        y_pred_test = model.predict_proba(X_preds)[:, 1]\n        test_preds.append(y_pred_test)\n    \n    # âœ… Average test predictions from 5 folds\n    final_test_preds = np.mean(test_preds, axis=0)\n    \n    # âœ… Convert to class labels with custom threshold\n    final_labels = (final_test_preds >= 0.4).astype(int)\n    \n    print(\"CV Mean F1:\", np.mean(f1_scores))\n    return final_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:25:29.382010Z","iopub.execute_input":"2025-07-29T12:25:29.382752Z","iopub.status.idle":"2025-07-29T12:25:29.390902Z","shell.execute_reply.started":"2025-07-29T12:25:29.382716Z","shell.execute_reply":"2025-07-29T12:25:29.389828Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"#y_pred = stratifiedKFold(best_xgb)\ny_pred = stratifiedKFold(best_lgbm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:25:29.715505Z","iopub.execute_input":"2025-07-29T12:25:29.715871Z","iopub.status.idle":"2025-07-29T12:25:33.899042Z","shell.execute_reply.started":"2025-07-29T12:25:29.715845Z","shell.execute_reply":"2025-07-29T12:25:33.897999Z"}},"outputs":[{"name":"stdout","text":"Fold 1\nFold 1 F1: 0.8167\nFold 2\nFold 2 F1: 0.8052\nFold 3\nFold 3 F1: 0.8439\nFold 4\nFold 4 F1: 0.8404\nFold 5\nFold 5 F1: 0.8199\nCV Mean F1: 0.8252046290406225\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"test_ids = test_df['ID'].values\n# Predict probabilities and classify as 0 or 1\n\n# Count the number of predictions for each class\nunique, counts = np.unique(y_pred, return_counts=True)\nprediction_counts = dict(zip(unique, counts))\nprint(\"Prediction counts:\", prediction_counts)\n\n# Prepare submission file\nsubmission_df = pd.DataFrame({\n    'ID': test_ids,\n    'label': y_pred.flatten()  # Flatten to match submission format\n})\nsubmission_df.to_csv('/kaggle/working/Submission_File.csv', index=False)\nprint(\"Sample submission file created as 'Submission_File.csv'.\")","metadata":{"id":"H7GNYIMl0Jbe","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T12:14:39.131742Z","iopub.execute_input":"2025-07-29T12:14:39.132116Z","iopub.status.idle":"2025-07-29T12:14:39.149114Z","shell.execute_reply.started":"2025-07-29T12:14:39.132088Z","shell.execute_reply":"2025-07-29T12:14:39.147948Z"}},"outputs":[{"name":"stdout","text":"Prediction counts: {0: 4723, 1: 675}\nSample submission file created as 'Submission_File.csv'.\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from xgboost import plot_importance\nplot_importance(best_xgb, importance_type='gain', max_num_features=20)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"### Explanation\n1. **Count Predictions**:\n   - After making predictions on `X_test`, we use `np.unique` with `return_counts=True` to count the occurrences of `0`s and `1`s in `y_test_pred`.\n   - We print the counts, which shows the distribution of predicted labels.\n\n2. **Interpretation**:\n   - The counts provide insight into whether the model is predicting a balanced number of `0`s and `1`s or if it's skewed towards one class.\n   - Please consider that the test set is imbalanced towards the non-landslide class.\n   - This check is particularly useful for binary classification problems where class imbalance could impact the modelâ€™s evaluation.\n\n3. **Prepare Submission File**:\n   - The `Submission_File.csv` file is created in the same way, ready for submission.","metadata":{"id":"DeyImf6L0Jbf"}}]}